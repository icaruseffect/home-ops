---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

tasks:
  setup:
    - task: config
    - task: kubeconfig
    - task: patch
    - task: apply-config

  init:
    desc: Initialize talos configuration
    dir: infra/talos
    cmds:
      # https://github.com/budimanjojo/talhelper
      - "talhelper gensecret > talsecret.sops.yaml"
      - "sops -e -i talsecret.sops.yaml"

  config:
    desc: Let talhelper generate the configuration files
    dir: infra/talos
    cmds:
      - "talhelper genconfig"

  patch:copy-mc:
    dir: infra/talos/contabo
    cmds:
      - cmd: cp controlplane.yaml machineconfig_patched.yaml

  patch:
    desc: Patch the machineconfig file
    dir: infra/talos/contabo
    deps: [patch:copy-mc]
    sources:
      - patches/*.yaml
    # generates:
    # - contabo/machineconfig_patched.yaml
    run: always
    cmds:
      - cmd: echo $PWD
      # - cmd: cp controlplane.yaml machineconfig_patched.yaml
      - cmd: ls -la
      - for: sources
        cmd: talosctl mc patch machineconfig_patched.yaml --patch @{{.ITEM}} > /tmp/machineconfig_tmp && cp /tmp/machineconfig_tmp machineconfig_patched.yaml
      - cmd: rm /tmp/machineconfig_tmp
    preconditions:
      # if template and patched file are the same after copying the template run the patches
      - sh: "[[ $(sha256sum machineconfig_patched.yaml | awk '{ print $1 }') = $(sha256sum controlplane.yaml | awk '{ print $1 }' ) ]]"
    requires:
      vars:
        - TALOSCONFIG

  bootstrap:apply-config-insecure:
    desc: Install contabo
    dir: infra/talos/contabo
    cmds:
      - |
        talosctl apply-config --insecure \
          --file machineconfig_patched.yaml \
          --nodes $NODE_IP

  bootstrap:apply-config-secure:
    desc: Install contabo
    dir: infra/talos/contabo
    cmds:
      - |
        talosctl apply-config  \
          --file machineconfig_patched.yaml \
          --nodes $NODE_IP

  update:talos01:
    desc: Update talos01
    dir: infra/talos
    cmds:
      - |
        talosctl apply-config \
          --nodes 192.168.1.51 \
          --file clusterconfig/talos-flux-talos01.yaml

  bootstrap:etcd:
    desc: Bootstrap talos etcd on contabo
    dir: infra/talos
    cmds:
      - |
        talosctl bootstrap \
          --talosconfig=clusterconfig/talosconfig \
          --nodes $NODE_IP

  kubeconfig:
    desc: write kube config
    dir: infra/talos
    cmds:
      - |
        talosctl kubeconfig \
          --talosconfig=$TALOSCONFIG \
          --force

  bootstrap:network:
    dir: kubernetes/talos-flux/
    cmds:
      - kubectl kustomize --enable-helm  --helm-command=$(which helm) bootstrap/cilium | kubectl apply -n kube-system -f -

  bootstrap:flux:
    dir: kubernetes/talos-flux/
    cmds:
      - kubectl apply --server-side -k flux/flux-manifests
      - sops decrypt flux/config/sops-age.sops.yaml | kubectl apply -n flux-system -f -
      - sops decrypt flux/config/cluster-secrets.sops.yaml | kubectl apply -n flux-system -f -
      - sops decrypt flux/config/github-ssh.sops.yaml | kubectl apply -n flux-system -f -
      - kubectl apply --server-side -f flux/repositories/home-ops.yaml
      - kubectl apply --server-side -f flux/flux-sync.yaml
      - kubectl apply --server-side -f flux/apps-sync.yaml

  cilium:delete-unmanaged-pods:
    cmd: kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,HOSTNETWORK:.spec.hostNetwork --no-headers=true | grep '<none>' | awk '{print "-n "$1" "$2"}' | xargs -L 1 -r kubectl delete pod

  cilium:rollOutRestart:
    cmd: kubectl -n kube-system rollout restart deployment/cilium-operator daemonset/cilium daemonset/cilium-envoy

  # dashboard:
  #   desc: start the theila dashboard
  #   cmds:
  #     - theila --address 127.0.0.1 --port 8080

  # https://www.talos.dev/v1.2/advanced/disaster-recovery/
  backup:etcd:
    desc: backup etcd from ip 192.168.1.51
    cmds:
      - talosctl -n 192.168.1.51 etcd snapshot db.snapshot

  dashboard:
    desc: Dashboard talos01
    dir: infra/talos
    cmds:
      - talosctl dashboard --nodes {{.hostname}}
    requires:
      vars:
        - hostname

  dashboard:talos01:
    desc: Dashboard talos01
    dir: infra/talos
    cmds:
      - |
        talosctl dashboard \
          --nodes 192.168.1.51
  reset:
    desc: Reset the machine and delete STATE and EPHEMERAL partition
    cmd: talosctl reset  --graceful=false  --system-labels-to-wipe STATE --system-labels-to-wipe EPHEMERAL --reboot

  upgrade:
    # usage: task talos:upgrade hostname=192.168.1.51 cluster=talos-flux
    desc: Upgrade talos on a node
    dir: infra/talos
    prompt: do you want to upgrade talos to {{.TALOS_VERSION}} on node {{.hostname}}?
    cmds:
      - until kubectl --context {{.KUBE_CONTEXT}} wait --timeout=5m --for=condition=Complete jobs --all --all-namespaces; do sleep 10; done
      - talosctl --context {{.cluster}} --nodes {{.hostname}} upgrade --image="ghcr.io/siderolabs/installer:{{.TALOS_VERSION}}" --wait=true --timeout=10m --preserve=true
      - talosctl --context {{.cluster}} --nodes {{.hostname}} health --wait-timeout=10m --server=false
      - until kubectl --context {{.KUBE_CONTEXT}} wait --timeout=5m --for=jsonpath=.status.ceph.health=HEALTH_OK cephcluster --all --all-namespaces; do sleep 10; done
    vars:
      TALOS_VERSION:
        sh: yq 'select(document_index == 0).talosVersion' {{.TALOS_DIR}}/talconfig.yaml
      KUBERNETES_VERSION:
        sh: yq 'select(document_index == 0).kubernetesVersion' {{.TALOS_DIR}}/talconfig.yaml
      # CONTROLLER:
      #   sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[]' | shuf -n 1
      KUBE_CONTEXT:
        sh: echo admin@{{.cluster}}
    requires:
      vars:
        - cluster
        - hostname
    preconditions:
      - test -f {{.TALOS_DIR}}/talconfig.yaml
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.hostname}} get machineconfig >/dev/null 2>&1

  kubelet:upgrade:
    desc: Upgrade kubelet on a node
    dir: infra/talos
    prompt: do you want to upgrade kubelet to {{.KUBELET_VERSION}} on node {{.hostname}}?
    cmds:
      - task: config
      - until kubectl --context {{.KUBE_CONTEXT}} wait --timeout=5m --for=jsonpath=.status.ceph.health=HEALTH_OK cephcluster --all --all-namespaces; do sleep 10; done
      - talosctl apply --nodes {{.ip }} --file clusterconfig/talos-flux-{{.hostname }}.yaml
      - talosctl --context {{.cluster}} --nodes {{.ip}} health --wait-timeout=10m --server=false
      - until kubectl --context {{.KUBE_CONTEXT}} wait --timeout=5m --for=jsonpath=.status.ceph.health=HEALTH_OK cephcluster --all --all-namespaces; do sleep 10; done
    vars:
      KUBE_CONTEXT:
        sh: echo admin@{{.cluster}}
      KUBERNETES_VERSION:
        sh: yq 'select(document_index == 0).kubernetesVersion' {{.TALOS_DIR}}/talconfig.yaml
    requires:
      vars:
        - cluster
        - hostname
        - ip
    preconditions:
      - test -f {{.TALOS_DIR}}/talconfig.yaml
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.ip}} get machineconfig >/dev/null 2>&1
